{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e01db0e",
   "metadata": {},
   "source": [
    "## Creating a Widrow-Hoff linear associator (Least Mean Squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740c9ab3",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d863d65b",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09442253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086a0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ran_vector(dim):\n",
    "    '''\n",
    "    Takes in a dimension and returns randomly generated unit vector of\n",
    "    th\n",
    "    at dimension from uniform distribution with mean 0.\n",
    "    \n",
    "    dim: number of dimensions for generated vectors\n",
    "    \n",
    "    returns:\n",
    "        a numpy array containing a randomly generated unit vector\n",
    "    '''\n",
    "    vec = []\n",
    "    for i in range(dim):\n",
    "            uni_x = rnd.random()\n",
    "            vec.append(uni_x)\n",
    "    array = np.array(vec)\n",
    "    \n",
    "    #make distribution mean 0 per hw directions\n",
    "    npvec = array - (np.mean(array))\n",
    "\n",
    "    #normalizes vector by dividing by vector length/magnitude\n",
    "    mag = math.sqrt(sum(npvec ** 2))\n",
    "    out = npvec / mag \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "192d2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_as(num_vectors,dim):\n",
    "    fi = many_vec(num_vectors,dim)\n",
    "    gi = many_vec(num_vectors,dim)\n",
    "    fi = fi / np.linalg.norm(fi, axis=1)[:, np.newaxis]\n",
    "    gi = gi / np.linalg.norm(gi, axis=1)[:, np.newaxis]\n",
    "\n",
    "    # (b) Compute the outer product matrices, Ai = gifiT\n",
    "    Ai = np.array([np.outer(gi[i], fi[i]) for i in range(num_vectors)])\n",
    "\n",
    "    # (c) Form the overall connectivity matrix, A, as the sum of the individual outer product matrices\n",
    "    A = np.sum(Ai, axis=0)\n",
    "\n",
    "    # (d) Test the resulting matrix A\n",
    "    # (i) Compute the predicted output, g', for each stored input, fi using A\n",
    "    g_prime = np.dot(A, fi.T).T\n",
    "\n",
    "    \n",
    "    # (iv) Test the selectivity of the system by generating a new set of 50 random vectors, let’s call them hi, and computing the predicted outputs (hi’) using the A matrix you constructed above (i.e., find the matrix product between each hi vector and A: Ahi).\n",
    "\n",
    "    pred = np.array(g_prime)\n",
    "    gs = np.array(gi)\n",
    "    squared_errors = np.sum((pred - gs) ** 2, axis=1)\n",
    "    return squared_errors\n",
    "    \n",
    "    \n",
    "    #print(\"Average length of hi':\", np.mean(length_hi_pred))\n",
    "   # print(\"Average length of gi:\", np.mean(length_gi))\n",
    "    #print(\"Average cosine:\", np.mean(cosine))\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85c05e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def many_vec(n,dim):\n",
    "    '''\n",
    "    runs ran_vector many times\n",
    "    '''\n",
    "    out = []\n",
    "    for i in range(n):\n",
    "        x = ran_vector(dim)\n",
    "        out.append(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a51c7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(vec):\n",
    "    '''\n",
    "    Computes the length of a vector.\n",
    "    \n",
    "    v: vector\n",
    "    return:\n",
    "        a float length of a vector\n",
    "    '''\n",
    "    vec = np.array(vec)\n",
    "    mag = math.sqrt(sum(vec ** 2))\n",
    "    return mag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af6059c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_norms(x):\n",
    "    '''\n",
    "    uses length function on many vectors\n",
    "    '''\n",
    "    x = np.array(x)\n",
    "    out = []\n",
    "    for i in range(len(x)):\n",
    "        s = norm(x[i])\n",
    "        out.append(s)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9dd9b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos(a,b):\n",
    "    len_a = np.linalg.norm(a)\n",
    "    len_b = np.linalg.norm(b)\n",
    "    norm_a = a/len_a\n",
    "    norm_b = b/len_b\n",
    "    cos_angle = np.dot(norm_a,norm_b)\n",
    "    return cos_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9551587c",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb1266e",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42864d53",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0e521a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wH(f,g,A,k=1):\n",
    "    Ai = np.array([np.outer(f, g)])\n",
    "    A = np.sum(Ai, axis=0)\n",
    "\n",
    "    # 3) compute the predicted output, g', for each stored input, fi, using A\n",
    "    g_prime = np.dot(A, f)\n",
    "\n",
    "    # 4) Create Delta a\n",
    "    delta_A = np.dot( k*(g-g_prime),f)\n",
    "\n",
    "    # 5) add delta_A to original A matrix\n",
    "    A = A + delta_A\n",
    "\n",
    "    # 6) predictions\n",
    "    pred = np.dot(A, f)\n",
    "    \n",
    "    return A,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee2550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72fadf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(pred, gs):\n",
    "    pred = np.array(pred)\n",
    "    gs = np.array(gs)\n",
    "    squared_errors = np.sum((pred - gs) ** 2, axis=1)\n",
    "    mse = np.mean(squared_errors)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac78a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMS (pairs,dim,threshold):\n",
    "    '''\n",
    "    Uses the Least Means Squares Algorithm to correct matrix A until\n",
    "    change in mean square error between iterations is below a threshold.\n",
    "    \n",
    "    pair: Pairs of random unit vectors. How many vectors in f and g each\n",
    "    dim: dimension of unit vectors\n",
    "    threshold: What the change in mean square error is for simulation to stop\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1) create f_set and g_set, pairs of many vectors of dim 100\n",
    "    s = np.random.rand(pairs,dim)\n",
    "    w = np.random.rand(pairs,dim)\n",
    "    z = np.random.rand(pairs,dim)\n",
    "    f_set = s / np.linalg.norm(s, axis=1)[:, np.newaxis]\n",
    "    g_set = w / np.linalg.norm(w, axis=1)[:, np.newaxis]\n",
    "    h_set = z / np.linalg.norm(z, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    #intialize A with zeros\n",
    "    A = np.zeros((pairs,dim))\n",
    "    \n",
    "    pred_list = []\n",
    "    gs = []\n",
    "    norms = [0]\n",
    "    trials = 1 #keeps track of how many time while loop occurs, has to start w 1 bc of K\n",
    "    sq_errors = [1] # keeps track of mean standard error\n",
    "    all_mse = [1]\n",
    "    \n",
    "  \n",
    "    while ( True ):# number of iterations of this loop is number of trials\n",
    "        randomList = [] #keeps track of which pairs used in one trial\n",
    "        for i in range(pairs-len(randomList)):\n",
    "            #make sure a random, but not sequential pair is picked\n",
    "            #also ensures entire group is being picked from, without replacement\n",
    "            \n",
    "            r = rnd.randint(1,pairs-1)\n",
    "            if r not in randomList: \n",
    "                randomList.append(r)\n",
    "                \n",
    "                #Pick a random pair t\n",
    "                f = f_set[r]\n",
    "                g = g_set[r]\n",
    "                #keep tracks of g vectors used\n",
    "                gs.append(g)\n",
    "                \n",
    "                #set K to constant / # of learning trials\n",
    "                k = 1 - trials\n",
    "                \n",
    "                #updating of A and predictions\n",
    "                A,pred= wH(f,g,A,k)\n",
    "                \n",
    "                #keep track of prediction vectors\n",
    "                pred_list.append(pred)\n",
    "            \n",
    "            #continues for loop if pair is already picked\n",
    "            else:\n",
    "                continue \n",
    "                \n",
    "        trials = trials + 1\n",
    "        \n",
    "        #if the change in mse between\n",
    "        mse = mean_squared_error(pred_list,gs)\n",
    "        all_mse.append(mse)\n",
    "        if (abs(all_mse[-2] - all_mse[-1]) < abs(threshold)): \n",
    "            break\n",
    "        else: \n",
    "            continue\n",
    "            \n",
    "       \n",
    "        #all_mse[1:] bc list intialized with 1\n",
    "        #trials - 1 bc intialized as 1\n",
    "    return all_mse[1:], trials-1\n",
    "   \n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4801caa",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21155771",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885cab47",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43717ee7",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963ee3a6",
   "metadata": {},
   "source": [
    "## Part A)\n",
    "- Both K values (k=0.1 and k = (1/(fiTfi)-epsilon)/j) resulted in oscillations of error vector length from about a little more than 0 and 0.4. The same oscillations occured even for the vector h, a vector not related to the association between f and g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efbd821",
   "metadata": {},
   "source": [
    "### Part ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b315a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMSa (pairs,dim,threshold,k):\n",
    "    '''\n",
    "    Uses the Least Means Squares Algorithm to correct matrix A until\n",
    "    change in mean square error between iterations is below a threshold.\n",
    "    \n",
    "    pair: Pairs of random unit vectors. How many vectors in f and g each\n",
    "    dim: dimension of unit vectors\n",
    "    threshold: What the change in mean square error is for simulation to stop\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1) create f_set and g_set, pairs of many vectors of dim 100\n",
    "    s = np.random.rand(pairs,dim)\n",
    "    w = np.random.rand(pairs,dim)\n",
    "    z = np.random.rand(pairs,dim)\n",
    "    f_set = s / np.linalg.norm(s, axis=1)[:, np.newaxis]\n",
    "    g_set = w / np.linalg.norm(w, axis=1)[:, np.newaxis]\n",
    "    h_set = z / np.linalg.norm(z, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    #intialize A with zeros\n",
    "    A = np.zeros((pairs,dim))\n",
    "    \n",
    "    pred_list = []\n",
    "    pred_list_h = []\n",
    "    gs = []\n",
    "    hs = []\n",
    "    norms = [0]\n",
    "    trials = 1 #keeps track of how many time while loop occurs, has to start w 1 bc of K\n",
    "    all_mse = [1]\n",
    "    \n",
    "  \n",
    "    while ( True ):# number of iterations of this loop is number of trials\n",
    "        randomList = [] #keeps track of which pairs used in one trial\n",
    "        for i in range(pairs-len(randomList)):\n",
    "            #make sure a random, but not sequential pair is picked\n",
    "            #also ensures entire group is being picked from, without replacement\n",
    "            \n",
    "            r = rnd.randint(1,pairs-1)\n",
    "            if r not in randomList: \n",
    "                randomList.append(r)\n",
    "                \n",
    "                #Pick a random pair t\n",
    "                f = f_set[r]\n",
    "                g = g_set[r]\n",
    "                h = h_set[r]\n",
    "                #keep tracks of g vectors used\n",
    "                gs.append(g)\n",
    "                \n",
    "                #set K to constant / # of learning trials\n",
    "                k = k\n",
    "                \n",
    "                #updating of A and predictions\n",
    "                A,pred= wH(f,g,A,k)\n",
    "                h_pred = np.dot(A,h)\n",
    "                \n",
    "                #keep track of prediction vectors\n",
    "                pred_list.append(pred)\n",
    "                pred_list_h.append(h_pred)\n",
    "            #continues for loop if pair is already picked\n",
    "            else:\n",
    "                continue \n",
    "                \n",
    "        trials = trials + 1\n",
    "        \n",
    "        #if the change in mse between\n",
    "        mse = mean_squared_error(pred_list,gs)\n",
    "        all_mse.append(mse)\n",
    "        if (abs(all_mse[-2] - all_mse[-1]) < abs(threshold)): \n",
    "            break\n",
    "        else: \n",
    "            continue\n",
    "            \n",
    "       \n",
    "        #all_mse[1:] bc list intialized with 1\n",
    "        #trials - 1 bc intialized as 1\n",
    "    #for normal return of mean error vectors with g prediction\n",
    "    #return np.array(find_norms(gs)) - np.array(find_norms(pred_list))\n",
    "   #for return of mean error vectors with h prediction\n",
    "    return np.array(find_norms(gs)) - np.array(find_norms(pred_list_h))\n",
    "    \n",
    "   \n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bba6dbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part a1) making oscillations when K is a constant. Different pair sizes \n",
    "A120= LMSa(20,100,0.0000001,0.1)\n",
    "A140= LMSa(40,100,0.0000001,0.1)\n",
    "A160= LMSa(60,100,0.0000001,0.1)\n",
    "A180= LMSa(80,100,0.0000001,0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6704bccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(2,2,1)\n",
    "plt.plot(A120,label = \"20 pairs\")\n",
    "plt.title(\"Oscillating Error Vectors when K =0.1 \")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(A140,label = \"40 pairs\", color = \"green\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(A160,label = \"60 pairs\", color = \"red\")\n",
    "plt.ylabel(\"Error Vector Length\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(A180,label = \"80 pairs\", color = \"orange\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf24288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(A120[200:250],label = \"20 pairs\")\n",
    "plt.plot(A180[200:250],label = \"80 pairs\",color = \"orange\")\n",
    "plt.title(\"Zoomed in of 20 pairs and 80 pairs Oscillation for K=0.1\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pred = LMSa(20,100,0.0000001,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2d585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h_pred)\n",
    "plt.title(\"vector error length for h predicted outputs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d869d5",
   "metadata": {},
   "source": [
    "### Part aii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ec32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMSaii (pairs,dim,threshold):\n",
    "    '''\n",
    "    Uses the Least Means Squares Algorithm to correct matrix A until\n",
    "    change in mean square error between iterations is below a threshold.\n",
    "    \n",
    "    pair: Pairs of random unit vectors. How many vectors in f and g each\n",
    "    dim: dimension of unit vectors\n",
    "    threshold: What the change in mean square error is for simulation to stop\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1) create f_set and g_set, pairs of many vectors of dim 100\n",
    "    s = np.random.rand(pairs,dim)\n",
    "    w = np.random.rand(pairs,dim)\n",
    "    f_set = s / np.linalg.norm(s, axis=1)[:, np.newaxis]\n",
    "    g_set = w / np.linalg.norm(w, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    #intialize A with zeros\n",
    "    A = np.zeros((pairs,dim))\n",
    "    \n",
    "    pred_list = []\n",
    "    gs = []\n",
    "    norms = [0]\n",
    "    trials = 1 #keeps track of how many time while loop occurs, has to start w 1 bc of K\n",
    "    sq_errors = [1] # keeps track of mean standard error\n",
    "    all_mse = [1]\n",
    "    \n",
    "  \n",
    "    while ( True ):# number of iterations of this loop is number of trials\n",
    "        randomList = [] #keeps track of which pairs used in one trial\n",
    "        for i in range(pairs-len(randomList)):\n",
    "            #make sure a random, but not sequential pair is picked\n",
    "            #also ensures entire group is being picked from, without replacement\n",
    "            \n",
    "            r = rnd.randint(1,pairs-1)\n",
    "            if r not in randomList: \n",
    "                randomList.append(r)\n",
    "                \n",
    "                #Pick a random pair t\n",
    "                f = f_set[r]\n",
    "                g = g_set[r]\n",
    "                #keep tracks of g vectors used\n",
    "                gs.append(g)\n",
    "                \n",
    "                \n",
    "                k = ((1/np.dot(f,f)) - (1/1000)) / trials\n",
    "                \n",
    "                #updating of A and predictions\n",
    "                A,pred= wH(f,g,A,k)\n",
    "                \n",
    "                #keep track of prediction vectors\n",
    "                pred_list.append(pred)\n",
    "            \n",
    "            #continues for loop if pair is already picked\n",
    "            else:\n",
    "                continue \n",
    "                \n",
    "        trials = trials + 1\n",
    "        \n",
    "        #if the change in mse between\n",
    "        mse = mean_squared_error(pred_list,gs)\n",
    "        all_mse.append(mse)\n",
    "        if (abs(all_mse[-2] - all_mse[-1]) < abs(threshold)): \n",
    "            break\n",
    "        else: \n",
    "            continue\n",
    "            \n",
    "    #for normal return of mean error vectors with g prediction\n",
    "    #return np.array(find_norms(gs)) - np.array(find_norms(pred_list))\n",
    "    \n",
    "    \n",
    "   #for return of mean error vectors with h prediction\n",
    "    return np.array(find_norms(gs)) - np.array(find_norms(pred_list_h))\n",
    "    \n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a7e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part aii) when K = 1/(fiTfi)-epsilon)/j\n",
    "Aii20= LMSaii(20,100,0.0000001)\n",
    "Aii40= LMSaii(40,100,0.0000001)\n",
    "Aii60= LMSaii(60,100,0.0000001)\n",
    "Aii80= LMSaii(80,100,0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607d165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(Aii20,label = \"20 pairs\")\n",
    "plt.title(\"Oscillating Error Vectors when K = 1/(fiTfi)-epsilon)/j \")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(Aii40,label = \"40 pairs\",color = \"green\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(Aii60,label = \"60 pairs\",color = \"red\")\n",
    "plt.ylabel(\"Error Vector Length\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(Aii80,label = \"80 pairs\",color = \"orange\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe67a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(Aii20[200:250],label = \"20 pairs\")\n",
    "plt.plot(Aii80[200:250],label = \"80 pairs\",color = \"orange\")\n",
    "plt.title(\"Zoomed in of 20 pairs and 80 pairs Oscillation when K = 1/(fiTfi)-epsilon)/j\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2880a782",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1c7a620",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7764e34",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b78acf",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb6fce",
   "metadata": {},
   "source": [
    "## Part b) Convergence\n",
    "- It seems like the more associations put into the system, the longer the system takes to converge to a mean squared error rate, except for when there is 80 pairs. According to my data, 80 pairs takes less iterations then 60 and 40. To investigate this more, I also plotted 1000 pairs and the number of iterations it took for the mean squared error to converge was the lowest out of any number of pairs.\n",
    "\n",
    "- I used k = 1 - (1/1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3171cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMSb (pairs,dim,threshold):\n",
    "    '''\n",
    "    Uses the Least Means Squares Algorithm to correct matrix A until\n",
    "    change in mean square error between iterations is below a threshold.\n",
    "    \n",
    "    pair: Pairs of random unit vectors. How many vectors in f and g each\n",
    "    dim: dimension of unit vectors\n",
    "    threshold: What the change in mean square error is for simulation to stop\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1) create f_set and g_set, pairs of many vectors of dim 100\n",
    "    s = np.random.rand(pairs,dim)\n",
    "    w = np.random.rand(pairs,dim)\n",
    "    f_set = s / np.linalg.norm(s, axis=1)[:, np.newaxis]\n",
    "    g_set = w / np.linalg.norm(w, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    #intialize A with zeros\n",
    "    A = np.zeros((pairs,dim))\n",
    "    \n",
    "    pred_list = []\n",
    "    gs = []\n",
    "    norms = [0]\n",
    "    trials = 1 #keeps track of how many time while loop occurs, has to start w 1 bc of K\n",
    "    sq_errors = [1] # keeps track of mean standard error\n",
    "    all_mse = [1]\n",
    "    associations = 1\n",
    "  \n",
    "    while ( True ):# number of iterations of this loop is number of trials\n",
    "        randomList = [] #keeps track of which pairs used in one trial\n",
    "        for i in range(pairs-len(randomList)):\n",
    "            #make sure a random, but not sequential pair is picked\n",
    "            #also ensures entire group is being picked from, without replacement\n",
    "            \n",
    "            r = rnd.randint(1,pairs-1)\n",
    "            if r not in randomList: \n",
    "                randomList.append(r)\n",
    "                \n",
    "                #Pick a random pair t\n",
    "                f = f_set[r]\n",
    "                g = g_set[r]\n",
    "                #keep tracks of g vectors used\n",
    "                gs.append(g)\n",
    "                \n",
    "                #set K to constant / # of learning trials\n",
    "                \n",
    "                k = 1 - (1/1000)\n",
    "                \n",
    "                #updating of A and predictions\n",
    "                A,pred= wH(f,g,A,k)\n",
    "                \n",
    "                #keep track of prediction vectors\n",
    "                pred_list.append(pred)\n",
    "                associations =  associations+1\n",
    "            \n",
    "            #continues for loop if pair is already picked\n",
    "            else:\n",
    "                continue \n",
    "                \n",
    "        trials = trials + 1\n",
    "        \n",
    "        #if the change in mse between\n",
    "        mse = mean_squared_error(pred_list,gs)\n",
    "        all_mse.append(mse)\n",
    "        if (abs(all_mse[-2] - all_mse[-1])) / all_mse[-1] < abs(threshold): \n",
    "            break\n",
    "        else: \n",
    "            continue\n",
    "            \n",
    "       \n",
    "        \n",
    "    return all_mse, associations\n",
    "    \n",
    "    \n",
    "   \n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca044ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "B20,y20= LMSb(20,100,0.000001)\n",
    "B40,y40= LMSb(40,100,0.000001)\n",
    "B60,y60= LMSb(60,100,0.000001)\n",
    "B80,y80= LMSb(80,100,0.000001)\n",
    "B1000,y1000= LMSb(1000,100,0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6991d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(2,2,1)\n",
    "plt.plot(B20[1:],label = \"20 pairs\")\n",
    "\n",
    "plt.title(\"Mean Square Error after Each Presentation of all Pairs for 1% Decrease in Error Rate\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(B40[1:],label = \"40 pairs\",color = \"green\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(B60[1:],label = \"60 pairs\",color = \"red\")\n",
    "plt.ylabel(\"Mean Square Errors\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(B80[1:],label = \"80 pairs\",color = \"orange\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(B1000[1:],label = \"1000 pairs\",color = \"purple\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4ef5da",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474913c1",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc78697b",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2118adf9",
   "metadata": {},
   "source": [
    "### Part C)\n",
    "- I tried to run my least means square function until the error vector between h and g was less than predicted g and g, but my system went into over 128000 pairs and still kept running. I had to stop the iterations because it was taking minutes. I found this out by printing pairs after each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMSc (pairs,dim,threshold):\n",
    "    '''\n",
    "    Uses the Least Means Squares Algorithm to correct matrix A until\n",
    "    change in mean square error between iterations is below a threshold.\n",
    "    \n",
    "    pair: Pairs of random unit vectors. How many vectors in f and g each\n",
    "    dim: dimension of unit vectors\n",
    "    threshold: What the change in mean square error is for simulation to stop\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1) create f_set and g_set, pairs of many vectors of dim 100\n",
    "    z = np.random.rand(pairs,dim)\n",
    "    s = np.random.rand(pairs,dim)\n",
    "    w = np.random.rand(pairs,dim)\n",
    "    \n",
    "    f_set = s / np.linalg.norm(s, axis=1)[:, np.newaxis]\n",
    "    g_set = w / np.linalg.norm(w, axis=1)[:, np.newaxis]\n",
    "    h_set = z / np.linalg.norm(z, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    #intialize A with zeros\n",
    "    A = np.zeros((pairs,dim))\n",
    "    \n",
    "    pred_list = []\n",
    "    gs = []\n",
    "    norms = [0]\n",
    "    trials = 1 #keeps track of how many time while loop occurs, has to start w 1 bc of K\n",
    "    sq_errors = [1] # keeps track of mean standard error\n",
    "    all_mse = [1]\n",
    "    \n",
    "    pred_list_h = []\n",
    "    all_mse_h = []\n",
    "    \n",
    "  \n",
    "    while ( True ):# number of iterations of this loop is number of trials\n",
    "        randomList = [] #keeps track of which pairs used in one trial\n",
    "        for i in range(pairs-len(randomList)):\n",
    "            #make sure a random, but not sequential pair is picked\n",
    "            #also ensures entire group is being picked from, without replacement\n",
    "            \n",
    "            r = rnd.randint(1,pairs-1)\n",
    "            if r not in randomList: \n",
    "                randomList.append(r)\n",
    "                \n",
    "                #Pick a random pair t\n",
    "                f = f_set[r]\n",
    "                g = g_set[r]\n",
    "                h = h_set[r]\n",
    "                #keep tracks of g vectors used\n",
    "                gs.append(g)\n",
    "                \n",
    "                #set K to constant / # of learning trials\n",
    "                k = 1 - trials\n",
    "                \n",
    "                #updating of A and predictions\n",
    "                A,pred= wH(f,g,A,k)\n",
    "                \n",
    "                #put h into A\n",
    "                pred_h = np.dot(A, h)\n",
    "                \n",
    "                #keep track of prediction vectors\n",
    "                pred_list.append(pred)\n",
    "                pred_list_h.append(pred_h)\n",
    "            \n",
    "            #continues for loop if pair is already picked\n",
    "            else:\n",
    "                continue \n",
    "                \n",
    "        trials = trials + 1\n",
    "        \n",
    "        #if the change in mse between\n",
    "        mse = mean_squared_error(pred_list,gs)\n",
    "        mse_h = mean_squared_error(pred_list_h,gs)\n",
    "        \n",
    "        all_mse.append(mse)\n",
    "        all_mse_h.append(mse_h)\n",
    "        \n",
    "        #error_length = np.array(find_norms(gs)) - np.array(find_norms(pred_list))\n",
    "        #if (np.mean(error_length) < threshold):\n",
    "        if (abs(all_mse[-2] - all_mse[-1]) < abs(threshold)): \n",
    "            break\n",
    "        else: \n",
    "            continue\n",
    "    gs = np.array(gs)\n",
    "    pred_list = np.array(pred_list)\n",
    "    return np.sqrt(np.sum((gs - pred_list)**2)) , np.sqrt(np.sum((gs - pred_list_h))**2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70653bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deterioation(dim,threshold):\n",
    "    pairs = 1000\n",
    "    errorVec_pairs= [0]\n",
    "    errorVec_h_pairs = [0]\n",
    "    \n",
    "    while (errorVec_pairs[-1] <= errorVec_h_pairs[-1]):\n",
    "        pairs = pairs * 2\n",
    "        error, error_h = LMSc(pairs,dim,threshold)\n",
    "        errorVec_pairs.append(error)\n",
    "        errorVec_h_pairs.append(error_h)\n",
    "        print(pairs)\n",
    "    return count, errorVec_pairs[-1], errorVec_h_pairs[-1],pairs\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd85e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "deterioation(100,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d5233",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93493daa",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f8d7f2",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b04806",
   "metadata": {},
   "source": [
    "## Part D\n",
    "- In a linear associator, the associations learned are dependent on the order in which they are presented. Therefore, if associations are presented in different requences, the model's weights and outputs would change, meaning different associations are being learned. However, if associations are presented sequentially in the Widrow-Hoff system, no learning more learning will occur, resulting in constant mean squared error rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56556d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMSdforwards (pairs,dim,threshold):\n",
    "    '''\n",
    "    Uses the Least Means Squares Algorithm to correct matrix A until\n",
    "    change in mean square error between iterations is below a threshold.\n",
    "    \n",
    "    pair: Pairs of random unit vectors. How many vectors in f and g each\n",
    "    dim: dimension of unit vectors\n",
    "    threshold: What the change in mean square error is for simulation to stop\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1) create f_set and g_set, pairs of many vectors of dim 100\n",
    "    s = np.random.rand(pairs,dim)\n",
    "    w = np.random.rand(pairs,dim)\n",
    "    f_set = s / np.linalg.norm(s, axis=1)[:, np.newaxis]\n",
    "    g_set = w / np.linalg.norm(w, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    #intialize A with zeros\n",
    "    A = np.zeros((pairs,dim))\n",
    "    \n",
    "    pred_list = []\n",
    "    gs = []\n",
    "    norms = [0]\n",
    "    trials = 1 #keeps track of how many time while loop occurs, has to start w 1 bc of K\n",
    "    sq_errors = [1] # keeps track of mean standard error\n",
    "    all_mse = [1]\n",
    "    \n",
    "  \n",
    "    while ( True ):# number of iterations of this loop is number of trials\n",
    "        \n",
    "        for r in range(pairs):\n",
    "            #make sure a random, but not sequential pair is picked\n",
    "            #also ensures entire group is being picked from, without replacement\n",
    "                \n",
    "                #Pick a random pair t\n",
    "                f = f_set[r]\n",
    "                g = g_set[r]\n",
    "                #keep tracks of g vectors used\n",
    "                gs.append(g)\n",
    "                \n",
    "                #set K to constant / # of learning trials\n",
    "                k = 1 - (1/1000)\n",
    "                \n",
    "                #updating of A and predictions\n",
    "                A,pred= wH(f,g,A,k)\n",
    "                \n",
    "                #keep track of prediction vectors\n",
    "                pred_list.append(pred)\n",
    "            \n",
    "        trials = trials + 1\n",
    "        \n",
    "        #if the change in mse between\n",
    "        mse = mean_squared_error(pred_list,gs)\n",
    "        all_mse.append(mse)\n",
    "        if (abs(all_mse[-2] - all_mse[-1]) < abs(threshold)): \n",
    "            break\n",
    "        else: \n",
    "            continue\n",
    "            \n",
    "       \n",
    "        #all_mse[1:] bc list intialized with 1\n",
    "        #trials - 1 bc intialized as 1\n",
    "    return all_mse[1:], trials-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb4f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# presents associations in sequence\n",
    "dfor20, trial_d120 = LMSdforwards(20,100,0.001)\n",
    "dfor40, trial_d140= LMSdforwards(40,100,0.001)\n",
    "dfor60, trial_d160= LMSdforwards(860,100,0.001)\n",
    "dfor80, trial_d180= LMSdforwards(80,100,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184180c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,2,1)\n",
    "plt.plot(dfor20,label = \"20 pairs\")\n",
    "plt.title(\"Changes in means squared error for Forwards Sequential Learning\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(dfor40,label = \"40 pairs\",color = \"green\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(dfor60,label = \"60 pairs\",color = \"red\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(dfor80,label = \"80 pairs\",color = \"orange\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMSdback(pairs,dim,threshold):\n",
    "    '''\n",
    "    Uses the Least Means Squares Algorithm to correct matrix A until\n",
    "    change in mean square error between iterations is below a threshold.\n",
    "    \n",
    "    pair: Pairs of random unit vectors. How many vectors in f and g each\n",
    "    dim: dimension of unit vectors\n",
    "    threshold: What the change in mean square error is for simulation to stop\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1) create f_set and g_set, pairs of many vectors of dim 100\n",
    "    s = np.random.rand(pairs,dim)\n",
    "    w = np.random.rand(pairs,dim)\n",
    "    f_set = s / np.linalg.norm(s, axis=1)[:, np.newaxis]\n",
    "    g_set = w / np.linalg.norm(w, axis=1)[:, np.newaxis]\n",
    "    \n",
    "    #intialize A with zeros\n",
    "    A = np.zeros((pairs,dim))\n",
    "    \n",
    "    pred_list = []\n",
    "    gs = []\n",
    "    norms = [0]\n",
    "    trials = 1 #keeps track of how many time while loop occurs, has to start w 1 bc of K\n",
    "    sq_errors = [1] # keeps track of mean standard error\n",
    "    all_mse = [1]\n",
    "    \n",
    "  \n",
    "    while ( True ):# number of iterations of this loop is number of trials\n",
    "        \n",
    "        for r in range(pairs,0,-1):\n",
    "            #make sure a random, but not sequential pair is picked\n",
    "            #also ensures entire group is being picked from, without replacement\n",
    "                \n",
    "                #Pick a random pair t\n",
    "                f = f_set[r]\n",
    "                g = g_set[r]\n",
    "                #keep tracks of g vectors used\n",
    "                gs.append(g)\n",
    "                \n",
    "                #set K to constant / # of learning trials\n",
    "                k = 1 - (1/1000)\n",
    "                \n",
    "                #updating of A and predictions\n",
    "                A,pred= wH(f,g,A,k)\n",
    "                \n",
    "                #keep track of prediction vectors\n",
    "                pred_list.append(pred)\n",
    "            \n",
    "        trials = trials + 1\n",
    "        \n",
    "        #if the change in mse between\n",
    "        mse = mean_squared_error(pred_list,gs)\n",
    "        all_mse.append(mse)\n",
    "        if (abs(all_mse[-2] - all_mse[-1]) < abs(threshold)): \n",
    "            break\n",
    "        else: \n",
    "            continue\n",
    "            \n",
    "       \n",
    "        #all_mse[1:] bc list intialized with 1\n",
    "        #trials - 1 bc intialized as 1\n",
    "    return all_mse[1:], trials-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27401d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dback20, trialb_d120 = LMSdforwards(20,100,0.001)\n",
    "dback40, trialb_d140= LMSdforwards(40,100,0.001)\n",
    "dback60, trialb_d160= LMSdforwards(860,100,0.001)\n",
    "dback80, trialb_d180= LMSdforwards(80,100,0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4542e79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.title(\"Changes in means squared error for Backwards Sequential Learning\")\n",
    "plt.plot(dback20,label = \"20 pairs\")\n",
    "\n",
    "plt.legend()\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(dback40,label = \"40 pairs\",color = \"green\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(dback60,label = \"60 pairs\",color = \"red\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(dback80,label = \"80 pairs\",color = \"orange\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa4cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = linear_as(20,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d4e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lin)\n",
    "plt.xlabel(\"pairs\")\n",
    "plt.title(\"Changes in MSE for Linear Associator with 20 pairs of 100 Dim Vectors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf124d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500108d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6b09b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c2462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ac0a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wH(f,g,A,k=1):\n",
    "   \n",
    "    # 3) compute the predicted output, g', for each stored input, fi, using A\n",
    "    g_prime = np.dot(A, f)\n",
    "\n",
    "    # 4) Create Delta a\n",
    "    delta_A = np.dot( k*(g-g_prime),f)\n",
    "\n",
    "    # 5) add delta_A to original A matrix\n",
    "    A = A + delta_A\n",
    "\n",
    "    # 6) predictions\n",
    "    pred = np.dot(A, f)\n",
    "    \n",
    "    return A,pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
